{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juRGczgb4fS2"
      },
      "source": [
        "Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFTFIYYQ2qEe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEvXqD8z4ki6"
      },
      "source": [
        "Распакова архива и генерация данных"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/drive/MyDrive/Flowers/flowers.zip -d flowers"
      ],
      "metadata": {
        "id": "g6CHC4lOeTZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders\n",
        "\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/flowers/flowers', output=\"output\", seed=1337, ratio=(.8, 0.1,0.1))"
      ],
      "metadata": {
        "id": "6L7vuoe0eQ_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPQcbb63MHM1"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/flowers/flowers'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "\n",
        "\n",
        "train_loader = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"./output/train\",\n",
        "    seed=123,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_loader = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"./output/test\",\n",
        "    seed=123,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "validation_loader = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"./output/val\",\n",
        "    seed=123,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "class_names = list(train_loader.class_names)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_loader.take(1):\n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\") / 255.0)\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"./output/train\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    \"./output/train\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', 'categorical_accuracy'])\n",
        "\n",
        "\n",
        "epochs = 25\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    \"./output/test\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "evaluation_results = model.evaluate(test_generator)\n",
        "test_loss = evaluation_results[0]\n",
        "test_acc = evaluation_results[1]\n",
        "print(f\"Accuracy on test data: {test_acc}\")\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in test_loader.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        predictions = model.predict(tf.expand_dims(images[i], 0))\n",
        "        score = tf.nn.softmax(predictions[0])\n",
        "        plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)])\n",
        "        plt.title(\"Actual: \"+class_names[labels[i]])\n",
        "        plt.gca().axes.yaxis.set_ticklabels([])\n",
        "        plt.gca().axes.xaxis.set_ticklabels([])"
      ],
      "metadata": {
        "id": "LoSZg1AserIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yE4MIXC5LEx"
      },
      "source": [
        "Сохранение модели"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.keras.utils.load_img(\n",
        "    \"/content/1.jpg\", target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    f\"Это изображение похоже на {class_names[np.argmax(score)]} с вероятностью {100 * np.max(score)} процентов.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "uLjKHtdge2Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"flowers.h5\")"
      ],
      "metadata": {
        "id": "hFECftbae33W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}